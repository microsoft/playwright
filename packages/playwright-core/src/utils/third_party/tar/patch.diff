diff --git a/original/extract.js b/patched/extract.js
index 739ebc9a9..b00f5d913 100644
--- a/original/extract.js
+++ b/patched/extract.js
@@ -1,15 +1,13 @@
-const { Writable, Readable, getStreamError } = require('streamx')
-const FIFO = require('fast-fifo')
-const b4a = require('b4a')
+const { Writable, Readable } = require('stream')
 const headers = require('./headers')
 
-const EMPTY = b4a.alloc(0)
+const EMPTY = Buffer.alloc(0)
 
 class BufferList {
   constructor () {
     this.buffered = 0
     this.shifted = 0
-    this.queue = new FIFO()
+    this.queue = []
 
     this._offset = 0
   }
@@ -38,11 +36,11 @@ class BufferList {
       chunks.push(chunk)
     }
 
-    return b4a.concat(chunks)
+    return Buffer.concat(chunks)
   }
 
   _next (size) {
-    const buf = this.queue.peek()
+    const buf = this.queue[0]
     const rem = buf.byteLength - this._offset
 
     if (size >= rem) {
@@ -71,18 +69,17 @@ class Source extends Readable {
     this._parent = self
   }
 
-  _read (cb) {
+  _read () {
     if (this.header.size === 0) {
       this.push(null)
     }
     if (this._parent._stream === this) {
       this._parent._update()
     }
-    cb(null)
   }
 
-  _predestroy () {
-    this._parent.destroy(getStreamError(this))
+  _predestroy(err) {
+    this._parent.destroy(err)
   }
 
   _detach () {
@@ -93,7 +90,7 @@ class Source extends Readable {
     }
   }
 
-  _destroy (cb) {
+  _destroy (err, cb) {
     this._detach()
     cb(null)
   }
@@ -281,7 +278,7 @@ class Extract extends Writable {
     cb(err)
   }
 
-  _write (data, cb) {
+  _write (data, encoding, cb) {
     this._callback = cb
     this._buffer.push(data)
     this._update()
@@ -296,101 +293,12 @@ class Extract extends Writable {
     this._continueWrite(null)
   }
 
-  _destroy (cb) {
-    if (this._stream) this._stream.destroy(getStreamError(this))
-    cb(null)
-  }
-
-  [Symbol.asyncIterator] () {
-    let error = null
-
-    let promiseResolve = null
-    let promiseReject = null
-
-    let entryStream = null
-    let entryCallback = null
-
-    const extract = this
-
-    this.on('entry', onentry)
-    this.on('error', (err) => { error = err })
-    this.on('close', onclose)
-
-    return {
-      [Symbol.asyncIterator] () {
-        return this
-      },
-      next () {
-        return new Promise(onnext)
-      },
-      return () {
-        return destroy(null)
-      },
-      throw (err) {
-        return destroy(err)
-      }
-    }
-
-    function consumeCallback (err) {
-      if (!entryCallback) return
-      const cb = entryCallback
-      entryCallback = null
-      cb(err)
-    }
-
-    function onnext (resolve, reject) {
-      if (error) {
-        return reject(error)
-      }
-
-      if (entryStream) {
-        resolve({ value: entryStream, done: false })
-        entryStream = null
-        return
-      }
-
-      promiseResolve = resolve
-      promiseReject = reject
-
-      consumeCallback(null)
-
-      if (extract._finished && promiseResolve) {
-        promiseResolve({ value: undefined, done: true })
-        promiseResolve = promiseReject = null
-      }
-    }
-
-    function onentry (header, stream, callback) {
-      entryCallback = callback
-      stream.on('error', noop) // no way around this due to tick sillyness
-
-      if (promiseResolve) {
-        promiseResolve({ value: stream, done: false })
-        promiseResolve = promiseReject = null
-      } else {
-        entryStream = stream
-      }
-    }
-
-    function onclose () {
-      consumeCallback(error)
-      if (!promiseResolve) return
-      if (error) promiseReject(error)
-      else promiseResolve({ value: undefined, done: true })
-      promiseResolve = promiseReject = null
-    }
-
-    function destroy (err) {
-      extract.destroy(err)
-      consumeCallback(err)
-      return new Promise((resolve, reject) => {
-        if (extract.destroyed) return resolve({ value: undefined, done: true })
-        extract.once('close', function () {
-          if (err) reject(err)
-          else resolve({ value: undefined, done: true })
-        })
-      })
+  _destroy (err, cb) {
+    if (this._stream) {
+      this._stream._predestroy(err)
+      this._stream.destroy(err)
     }
+    cb(null)
   }
 }
 
@@ -403,4 +311,4 @@ function noop () {}
 function overflow (size) {
   size &= 511
   return size && 512 - size
-}
\ No newline at end of file
+}
diff --git a/original/headers.js b/patched/headers.js
index 9161a7e86..b748e22b3 100644
--- a/original/headers.js
+++ b/patched/headers.js
@@ -1,13 +1,7 @@
-const b4a = require('b4a')
-
-const ZEROS = '0000000000000000000'
-const SEVENS = '7777777777777777777'
 const ZERO_OFFSET = '0'.charCodeAt(0)
-const USTAR_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x00]) // ustar\x00
-const USTAR_VER = b4a.from([ZERO_OFFSET, ZERO_OFFSET])
-const GNU_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x20]) // ustar\x20
-const GNU_VER = b4a.from([0x20, 0x00])
-const MASK = 0o7777
+const USTAR_MAGIC = Buffer.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x00]) // ustar\x00
+const GNU_MAGIC = Buffer.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x20]) // ustar\x20
+const GNU_VER = Buffer.from([0x20, 0x00])
 const MAGIC_OFFSET = 257
 const VERSION_OFFSET = 263
 
@@ -15,29 +9,16 @@ exports.decodeLongPath = function decodeLongPath (buf, encoding) {
   return decodeStr(buf, 0, buf.length, encoding)
 }
 
-exports.encodePax = function encodePax (opts) { // TODO: encode more stuff in pax
-  let result = ''
-  if (opts.name) result += addLength(' path=' + opts.name + '\n')
-  if (opts.linkname) result += addLength(' linkpath=' + opts.linkname + '\n')
-  const pax = opts.pax
-  if (pax) {
-    for (const key in pax) {
-      result += addLength(' ' + key + '=' + pax[key] + '\n')
-    }
-  }
-  return b4a.from(result)
-}
-
 exports.decodePax = function decodePax (buf) {
   const result = {}
 
   while (buf.length) {
     let i = 0
     while (i < buf.length && buf[i] !== 32) i++
-    const len = parseInt(b4a.toString(buf.subarray(0, i)), 10)
+    const len = parseInt(buf.toString('ascii', 0, i), 10)
     if (!len) return result
 
-    const b = b4a.toString(buf.subarray(i + 1, len - 1))
+    const b = buf.subarray('ascii', i + 1, len - 1)
     const keyIndex = b.indexOf('=')
     if (keyIndex === -1) return result
     result[b.slice(0, keyIndex)] = b.slice(keyIndex + 1)
@@ -48,49 +29,6 @@ exports.decodePax = function decodePax (buf) {
   return result
 }
 
-exports.encode = function encode (opts) {
-  const buf = b4a.alloc(512)
-  let name = opts.name
-  let prefix = ''
-
-  if (opts.typeflag === 5 && name[name.length - 1] !== '/') name += '/'
-  if (b4a.byteLength(name) !== name.length) return null // utf-8
-
-  while (b4a.byteLength(name) > 100) {
-    const i = name.indexOf('/')
-    if (i === -1) return null
-    prefix += prefix ? '/' + name.slice(0, i) : name.slice(0, i)
-    name = name.slice(i + 1)
-  }
-
-  if (b4a.byteLength(name) > 100 || b4a.byteLength(prefix) > 155) return null
-  if (opts.linkname && b4a.byteLength(opts.linkname) > 100) return null
-
-  b4a.write(buf, name)
-  b4a.write(buf, encodeOct(opts.mode & MASK, 6), 100)
-  b4a.write(buf, encodeOct(opts.uid, 6), 108)
-  b4a.write(buf, encodeOct(opts.gid, 6), 116)
-  encodeSize(opts.size, buf, 124)
-  b4a.write(buf, encodeOct((opts.mtime.getTime() / 1000) | 0, 11), 136)
-
-  buf[156] = ZERO_OFFSET + toTypeflag(opts.type)
-
-  if (opts.linkname) b4a.write(buf, opts.linkname, 157)
-
-  b4a.copy(USTAR_MAGIC, buf, MAGIC_OFFSET)
-  b4a.copy(USTAR_VER, buf, VERSION_OFFSET)
-  if (opts.uname) b4a.write(buf, opts.uname, 265)
-  if (opts.gname) b4a.write(buf, opts.gname, 297)
-  b4a.write(buf, encodeOct(opts.devmajor || 0, 6), 329)
-  b4a.write(buf, encodeOct(opts.devminor || 0, 6), 337)
-
-  if (prefix) b4a.write(buf, prefix, 345)
-
-  b4a.write(buf, encodeOct(cksum(buf), 6), 148)
-
-  return buf
-}
-
 exports.decode = function decode (buf, filenameEncoding, allowUnknownFormat) {
   let typeflag = buf[156] === 0 ? 0 : buf[156] - ZERO_OFFSET
 
@@ -149,12 +87,12 @@ exports.decode = function decode (buf, filenameEncoding, allowUnknownFormat) {
 }
 
 function isUSTAR (buf) {
-  return b4a.equals(USTAR_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6))
+  return USTAR_MAGIC.equals(buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6))
 }
 
 function isGNU (buf) {
-  return b4a.equals(GNU_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) &&
-    b4a.equals(GNU_VER, buf.subarray(VERSION_OFFSET, VERSION_OFFSET + 2))
+  return GNU_MAGIC.equals(buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) &&
+    GNU_VER.equals(buf.subarray(VERSION_OFFSET, VERSION_OFFSET + 2))
 }
 
 function clamp (index, len, defaultValue) {
@@ -199,31 +137,6 @@ function toType (flag) {
   return null
 }
 
-function toTypeflag (flag) {
-  switch (flag) {
-    case 'file':
-      return 0
-    case 'link':
-      return 1
-    case 'symlink':
-      return 2
-    case 'character-device':
-      return 3
-    case 'block-device':
-      return 4
-    case 'directory':
-      return 5
-    case 'fifo':
-      return 6
-    case 'contiguous-file':
-      return 7
-    case 'pax-header':
-      return 72
-  }
-
-  return 0
-}
-
 function indexOf (block, num, offset, end) {
   for (; offset < end; offset++) {
     if (block[offset] === num) return offset
@@ -238,28 +151,6 @@ function cksum (block) {
   return sum
 }
 
-function encodeOct (val, n) {
-  val = val.toString(8)
-  if (val.length > n) return SEVENS.slice(0, n) + ' '
-  return ZEROS.slice(0, n - val.length) + val + ' '
-}
-
-function encodeSizeBin (num, buf, off) {
-  buf[off] = 0x80
-  for (let i = 11; i > 0; i--) {
-    buf[off + i] = num & 0xff
-    num = Math.floor(num / 0x100)
-  }
-}
-
-function encodeSize (num, buf, off) {
-  if (num.toString(8).length > 11) {
-    encodeSizeBin(num, buf, off)
-  } else {
-    b4a.write(buf, encodeOct(num, 11), off)
-  }
-}
-
 /* Copied from the node-tar repo and modified to meet
  * tar-stream coding standard.
  *
@@ -304,18 +195,10 @@ function decodeOct (val, offset, length) {
     const end = clamp(indexOf(val, 32, offset, val.length), val.length, val.length)
     while (offset < end && val[offset] === 0) offset++
     if (end === offset) return 0
-    return parseInt(b4a.toString(val.subarray(offset, end)), 8)
+    return parseInt(val.toString('ascii', offset, end), 8)
   }
 }
 
 function decodeStr (val, offset, length, encoding) {
-  return b4a.toString(val.subarray(offset, indexOf(val, 0, offset, offset + length)), encoding)
+  return val.toString(encoding, offset, indexOf(val, 0, offset, offset + length))
 }
-
-function addLength (str) {
-  const len = b4a.byteLength(str)
-  let digits = Math.floor(Math.log(len) / Math.log(10)) + 1
-  if (len + digits >= Math.pow(10, digits)) digits++
-
-  return (len + digits) + str
-}
\ No newline at end of file
diff --git a/original/index.js b/patched/index.js
index 4bed3324b..812a9ed0f 100644
--- a/original/index.js
+++ b/patched/index.js
@@ -1,108 +1,10 @@
-const tar = require('tar-stream')
-const pump = require('pump')
+const tarExtract = require('./extract')
 const fs = require('fs')
 const path = require('path')
+const { pipeline } = require('stream/promises')
 
-const win32 = (global.Bare?.platform || process.platform) === 'win32'
+const win32 = process.platform === 'win32'
 
-exports.pack = function pack (cwd, opts) {
-  if (!cwd) cwd = '.'
-  if (!opts) opts = {}
-
-  const xfs = opts.fs || fs
-  const ignore = opts.ignore || opts.filter || noop
-  const mapStream = opts.mapStream || echo
-  const statNext = statAll(xfs, opts.dereference ? xfs.stat : xfs.lstat, cwd, ignore, opts.entries, opts.sort)
-  const strict = opts.strict !== false
-  const umask = typeof opts.umask === 'number' ? ~opts.umask : ~processUmask()
-  const pack = opts.pack || tar.pack()
-  const finish = opts.finish || noop
-
-  let map = opts.map || noop
-  let dmode = typeof opts.dmode === 'number' ? opts.dmode : 0
-  let fmode = typeof opts.fmode === 'number' ? opts.fmode : 0
-
-  if (opts.strip) map = strip(map, opts.strip)
-
-  if (opts.readable) {
-    dmode |= parseInt(555, 8)
-    fmode |= parseInt(444, 8)
-  }
-  if (opts.writable) {
-    dmode |= parseInt(333, 8)
-    fmode |= parseInt(222, 8)
-  }
-
-  onnextentry()
-
-  function onsymlink (filename, header) {
-    xfs.readlink(path.join(cwd, filename), function (err, linkname) {
-      if (err) return pack.destroy(err)
-      header.linkname = normalize(linkname)
-      pack.entry(header, onnextentry)
-    })
-  }
-
-  function onstat (err, filename, stat) {
-    if (pack.destroyed) return
-    if (err) return pack.destroy(err)
-    if (!filename) {
-      if (opts.finalize !== false) pack.finalize()
-      return finish(pack)
-    }
-
-    if (stat.isSocket()) return onnextentry() // tar does not support sockets...
-
-    let header = {
-      name: normalize(filename),
-      mode: (stat.mode | (stat.isDirectory() ? dmode : fmode)) & umask,
-      mtime: stat.mtime,
-      size: stat.size,
-      type: 'file',
-      uid: stat.uid,
-      gid: stat.gid
-    }
-
-    if (stat.isDirectory()) {
-      header.size = 0
-      header.type = 'directory'
-      header = map(header) || header
-      return pack.entry(header, onnextentry)
-    }
-
-    if (stat.isSymbolicLink()) {
-      header.size = 0
-      header.type = 'symlink'
-      header = map(header) || header
-      return onsymlink(filename, header)
-    }
-
-    // TODO: add fifo etc...
-
-    header = map(header) || header
-
-    if (!stat.isFile()) {
-      if (strict) return pack.destroy(new Error('unsupported type for ' + filename))
-      return onnextentry()
-    }
-
-    const entry = pack.entry(header, onnextentry)
-    const rs = mapStream(xfs.createReadStream(path.join(cwd, filename), { start: 0, end: header.size > 0 ? header.size - 1 : header.size }), header)
-
-    rs.on('error', function (err) { // always forward errors on destroy
-      entry.destroy(err)
-    })
-
-    pump(rs, entry)
-  }
-
-  function onnextentry (err) {
-    if (err) return pack.destroy(err)
-    statNext(onstat)
-  }
-
-  return pack
-}
 
 function head (list) {
   return list.length ? list[list.length - 1] : null
@@ -124,7 +26,7 @@ exports.extract = function extract (cwd, opts) {
   const ignore = opts.ignore || opts.filter || noop
   const mapStream = opts.mapStream || echo
   const own = opts.chown !== false && !win32 && processGetuid() === 0
-  const extract = opts.extract || tar.extract()
+  const extract = opts.extract || tarExtract()
   const stack = []
   const now = new Date()
   const umask = typeof opts.umask === 'number' ? ~opts.umask : ~processUmask()
@@ -244,10 +146,7 @@ exports.extract = function extract (cwd, opts) {
         rs.destroy(err)
       })
 
-      pump(rs, ws, function (err) {
-        if (err) return next(err)
-        ws.on('close', stat)
-      })
+      pipeline(rs, ws).then(stat).catch(next);
     }
   }
 
@@ -325,37 +224,6 @@ function normalize (name) {
   return win32 ? name.replace(/\\/g, '/').replace(/[:?<>|]/g, '_') : name
 }
 
-function statAll (fs, stat, cwd, ignore, entries, sort) {
-  if (!entries) entries = ['.']
-  const queue = entries.slice(0)
-
-  return function loop (callback) {
-    if (!queue.length) return callback(null)
-
-    const next = queue.shift()
-    const nextAbs = path.join(cwd, next)
-
-    stat.call(fs, nextAbs, function (err, stat) {
-      // ignore errors if the files were deleted while buffering
-      if (err) return callback(entries.indexOf(next) === -1 && err.code === 'ENOENT' ? null : err)
-
-      if (!stat.isDirectory()) return callback(null, next, stat)
-
-      fs.readdir(nextAbs, function (err, files) {
-        if (err) return callback(err)
-
-        if (sort) files.sort()
-
-        for (let i = 0; i < files.length; i++) {
-          if (!ignore(path.join(cwd, next, files[i]))) queue.push(path.join(next, files[i]))
-        }
-
-        callback(null, next, stat)
-      })
-    })
-  }
-}
-
 function strip (map, level) {
   return function (header) {
     header.name = header.name.split('/').slice(level).join('/')
@@ -367,4 +235,4 @@ function strip (map, level) {
 
     return map(header)
   }
-}
\ No newline at end of file
+}
